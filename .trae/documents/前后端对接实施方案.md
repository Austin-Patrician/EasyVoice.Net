# EasyVoice.Net 前后端对接实施方案

## 1. 实施概述

本文档详细说明如何将前端React的`RealTimeService`与后端C#的`DoubaoRealTimeService`进行对接，实现完整的实时语音对话功能。实施方案采用HTTP API管理会话生命周期，WebSocket处理实时音频流的架构设计。

## 2. 后端实施方案

### 2.1 增强RealTimeController

基于现有的`RealTimeController.cs`，需要添加以下增强功能：

```csharp
// 添加到 RealTimeController.cs

[ApiController]
[Route("api/[controller]")]
public class RealTimeController : ControllerBase
{
    private readonly IDoubaoRealTimeService _realTimeService;
    private readonly ILogger<RealTimeController> _logger;
    private readonly IMemoryCache _sessionCache;
    
    public RealTimeController(
        IDoubaoRealTimeService realTimeService,
        ILogger<RealTimeController> logger,
        IMemoryCache sessionCache)
    {
        _realTimeService = realTimeService;
        _logger = logger;
        _sessionCache = sessionCache;
    }

    /// <summary>
    /// 创建实时语音会话
    /// </summary>
    [HttpPost("session/create")]
    public async Task<IActionResult> CreateSession([FromBody] CreateSessionRequest request)
    {
        try
        {
            var sessionId = Guid.NewGuid().ToString();
            var config = new RealTimeConnectionConfig
            {
                AppId = request.AppId,
                AccessToken = request.AccessToken,
                WebSocketUrl = request.WebSocketUrl ?? "wss://openspeech.bytedance.com/api/v3/realtime/dialogue",
                ConnectionTimeoutMs = request.ConnectionTimeoutMs ?? 30000,
                AudioBufferSeconds = request.AudioBufferSeconds ?? 100
            };

            // 缓存会话配置
            _sessionCache.Set(sessionId, config, TimeSpan.FromHours(1));
            
            _logger.LogInformation("会话创建成功: {SessionId}", sessionId);
            
            return Ok(new CreateSessionResponse
            {
                SessionId = sessionId,
                Status = "created",
                Message = "会话创建成功"
            });
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "创建会话失败");
            return BadRequest(new { error = "创建会话失败", details = ex.Message });
        }
    }

    /// <summary>
    /// 启动会话连接
    /// </summary>
    [HttpPost("session/{sessionId}/start")]
    public async Task<IActionResult> StartSession(string sessionId, [FromBody] StartSessionRequest request)
    {
        try
        {
            if (!_sessionCache.TryGetValue(sessionId, out RealTimeConnectionConfig config))
            {
                return NotFound(new { error = "会话不存在" });
            }

            // 初始化DoubaoRealTimeService
            await _realTimeService.InitializeAsync(config);
            
            // 启动会话
            var payload = new StartSessionPayload
            {
                Tts = new TtsConfig
                {
                    AudioConfig = request.AudioConfig ?? new AudioConfig
                    {
                        Channel = 1,
                        Format = "pcm",
                        SampleRate = 24000
                    }
                },
                Dialog = new DialogConfig
                {
                    BotName = request.BotName ?? "豆包",
                    SystemRole = request.SystemRole ?? "你使用活泼灵动的女声，性格开朗，热爱生活。",
                    SpeakingStyle = request.SpeakingStyle ?? "你的说话风格简洁明了，语速适中，语调自然。"
                }
            };

            await _realTimeService.StartSessionAsync(payload);
            
            // 更新会话状态
            var sessionInfo = new SessionInfo
            {
                SessionId = sessionId,
                CreatedAt = DateTime.UtcNow,
                State = RealTimeDialogState.Connected
            };
            _sessionCache.Set($"session_info_{sessionId}", sessionInfo, TimeSpan.FromHours(1));
            
            _logger.LogInformation("会话启动成功: {SessionId}", sessionId);
            
            return Ok(new { status = "started", message = "会话启动成功" });
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "启动会话失败: {SessionId}", sessionId);
            return BadRequest(new { error = "启动会话失败", details = ex.Message });
        }
    }

    /// <summary>
    /// 获取会话状态
    /// </summary>
    [HttpGet("session/{sessionId}/status")]
    public IActionResult GetSessionStatus(string sessionId)
    {
        try
        {
            if (!_sessionCache.TryGetValue($"session_info_{sessionId}", out SessionInfo sessionInfo))
            {
                return NotFound(new { error = "会话不存在" });
            }

            var status = new SessionStatusResponse
            {
                SessionId = sessionId,
                State = sessionInfo.State.ToString(),
                CreatedAt = sessionInfo.CreatedAt,
                LastActiveAt = sessionInfo.LastActiveAt,
                IsConnected = sessionInfo.State == RealTimeDialogState.Connected
            };

            return Ok(status);
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "获取会话状态失败: {SessionId}", sessionId);
            return BadRequest(new { error = "获取会话状态失败", details = ex.Message });
        }
    }

    /// <summary>
    /// WebSocket音频流连接
    /// </summary>
    [HttpGet("session/{sessionId}/websocket")]
    public async Task<IActionResult> WebSocketConnection(string sessionId)
    {
        if (!HttpContext.WebSockets.IsWebSocketRequest)
        {
            return BadRequest("需要WebSocket连接");
        }

        if (!_sessionCache.TryGetValue(sessionId, out RealTimeConnectionConfig config))
        {
            return NotFound(new { error = "会话不存在" });
        }

        try
        {
            var webSocket = await HttpContext.WebSockets.AcceptWebSocketAsync();
            _logger.LogInformation("WebSocket连接建立: {SessionId}", sessionId);
            
            await HandleWebSocketConnection(sessionId, webSocket);
            
            return new EmptyResult();
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "WebSocket连接失败: {SessionId}", sessionId);
            return BadRequest(new { error = "WebSocket连接失败", details = ex.Message });
        }
    }

    /// <summary>
    /// 处理WebSocket连接
    /// </summary>
    private async Task HandleWebSocketConnection(string sessionId, WebSocket webSocket)
    {
        var buffer = new byte[4096];
        
        try
        {
            // 设置事件处理器
            _realTimeService.OnAudioDataReceived += async (audioData) =>
            {
                if (webSocket.State == WebSocketState.Open)
                {
                    await webSocket.SendAsync(
                        new ArraySegment<byte>(audioData),
                        WebSocketMessageType.Binary,
                        true,
                        CancellationToken.None);
                }
            };

            _realTimeService.OnDialogEvent += async (eventData) =>
            {
                if (webSocket.State == WebSocketState.Open)
                {
                    var message = JsonSerializer.Serialize(eventData);
                    var messageBytes = Encoding.UTF8.GetBytes(message);
                    await webSocket.SendAsync(
                        new ArraySegment<byte>(messageBytes),
                        WebSocketMessageType.Text,
                        true,
                        CancellationToken.None);
                }
            };

            // 接收客户端音频数据
            while (webSocket.State == WebSocketState.Open)
            {
                var result = await webSocket.ReceiveAsync(
                    new ArraySegment<byte>(buffer),
                    CancellationToken.None);

                if (result.MessageType == WebSocketMessageType.Binary)
                {
                    var audioData = new byte[result.Count];
                    Array.Copy(buffer, audioData, result.Count);
                    
                    // 发送音频数据到豆包服务
                    await _realTimeService.SendAudioDataAsync(audioData);
                }
                else if (result.MessageType == WebSocketMessageType.Close)
                {
                    await webSocket.CloseAsync(
                        WebSocketCloseStatus.NormalClosure,
                        "连接关闭",
                        CancellationToken.None);
                    break;
                }
            }
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "WebSocket处理异常: {SessionId}", sessionId);
        }
        finally
        {
            // 更新会话状态
            if (_sessionCache.TryGetValue($"session_info_{sessionId}", out SessionInfo sessionInfo))
            {
                sessionInfo.State = RealTimeDialogState.Disconnected;
                sessionInfo.LastActiveAt = DateTime.UtcNow;
                _sessionCache.Set($"session_info_{sessionId}", sessionInfo, TimeSpan.FromHours(1));
            }
            
            _logger.LogInformation("WebSocket连接关闭: {SessionId}", sessionId);
        }
    }
}

// 请求和响应模型
public class CreateSessionRequest
{
    public string AppId { get; set; } = string.Empty;
    public string AccessToken { get; set; } = string.Empty;
    public string? WebSocketUrl { get; set; }
    public int? ConnectionTimeoutMs { get; set; }
    public int? AudioBufferSeconds { get; set; }
}

public class CreateSessionResponse
{
    public string SessionId { get; set; } = string.Empty;
    public string Status { get; set; } = string.Empty;
    public string Message { get; set; } = string.Empty;
}

public class SessionStatusResponse
{
    public string SessionId { get; set; } = string.Empty;
    public string State { get; set; } = string.Empty;
    public DateTime CreatedAt { get; set; }
    public DateTime? LastActiveAt { get; set; }
    public bool IsConnected { get; set; }
}
```

### 2.2 增强DoubaoRealTimeService

在现有的`DoubaoRealTimeService.cs`基础上添加事件处理：

```csharp
// 添加到 DoubaoRealTimeService.cs

public class DoubaoRealTimeService : IDoubaoRealTimeService
{
    // 添加事件定义
    public event Func<byte[], Task>? OnAudioDataReceived;
    public event Func<RealTimeEventData, Task>? OnDialogEvent;
    public event Func<string, Task>? OnConnectionStateChanged;
    public event Func<Exception, Task>? OnError;

    // 现有代码...

    /// <summary>
    /// 初始化服务
    /// </summary>
    public async Task InitializeAsync(RealTimeConnectionConfig config)
    {
        _config = config;
        _logger.LogInformation("DoubaoRealTimeService初始化完成");
    }

    /// <summary>
    /// 发送音频数据
    /// </summary>
    public async Task SendAudioDataAsync(byte[] audioData)
    {
        try
        {
            if (_webSocket?.State == WebSocketState.Open)
            {
                // 构造音频消息
                var message = new ProtocolMessage
                {
                    Type = MessageType.AudioOnlyClient,
                    Sequence = _sequenceNumber++,
                    Payload = audioData
                };

                var messageBytes = SerializeMessage(message);
                await _webSocket.SendAsync(
                    new ArraySegment<byte>(messageBytes),
                    WebSocketMessageType.Binary,
                    true,
                    CancellationToken.None);

                _logger.LogDebug("发送音频数据: {Length}字节", audioData.Length);
            }
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "发送音频数据失败");
            await OnError?.Invoke(ex);
        }
    }

    /// <summary>
    /// 处理接收到的消息
    /// </summary>
    private async Task HandleReceivedMessage(byte[] messageData)
    {
        try
        {
            var message = DeserializeMessage(messageData);
            
            switch (message.Type)
            {
                case MessageType.AudioOnlyServer:
                    // 接收到音频数据
                    await OnAudioDataReceived?.Invoke(message.Payload);
                    break;
                    
                case MessageType.FullServer:
                    // 处理完整消息（包含文本和音频）
                    var eventData = ParseEventData(message.Payload);
                    await OnDialogEvent?.Invoke(eventData);
                    break;
                    
                case MessageType.Error:
                    // 处理错误消息
                    var errorMessage = Encoding.UTF8.GetString(message.Payload);
                    _logger.LogError("收到错误消息: {Error}", errorMessage);
                    await OnError?.Invoke(new Exception(errorMessage));
                    break;
            }
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "处理接收消息失败");
            await OnError?.Invoke(ex);
        }
    }

    /// <summary>
    /// 序列化协议消息
    /// </summary>
    private byte[] SerializeMessage(ProtocolMessage message)
    {
        // 实现消息序列化逻辑
        // 根据豆包协议格式进行序列化
        var header = new byte[8];
        BitConverter.GetBytes((int)message.Type).CopyTo(header, 0);
        BitConverter.GetBytes(message.Sequence).CopyTo(header, 4);
        
        var result = new byte[header.Length + message.Payload.Length];
        header.CopyTo(result, 0);
        message.Payload.CopyTo(result, header.Length);
        
        return result;
    }

    /// <summary>
    /// 反序列化协议消息
    /// </summary>
    private ProtocolMessage DeserializeMessage(byte[] data)
    {
        // 实现消息反序列化逻辑
        var type = (MessageType)BitConverter.ToInt32(data, 0);
        var sequence = BitConverter.ToInt32(data, 4);
        var payload = new byte[data.Length - 8];
        Array.Copy(data, 8, payload, 0, payload.Length);
        
        return new ProtocolMessage
        {
            Type = type,
            Sequence = sequence,
            Payload = payload
        };
    }

    /// <summary>
    /// 解析事件数据
    /// </summary>
    private RealTimeEventData ParseEventData(byte[] payload)
    {
        var jsonString = Encoding.UTF8.GetString(payload);
        return JsonSerializer.Deserialize<RealTimeEventData>(jsonString) ?? new RealTimeEventData();
    }
}

// 支持类型定义
public class RealTimeConnectionConfig
{
    public string AppId { get; set; } = string.Empty;
    public string AccessToken { get; set; } = string.Empty;
    public string WebSocketUrl { get; set; } = "wss://openspeech.bytedance.com/api/v3/realtime/dialogue";
    public int ConnectionTimeoutMs { get; set; } = 30000;
    public int AudioBufferSeconds { get; set; } = 100;
    public int InputSampleRate { get; set; } = 16000;
    public int OutputSampleRate { get; set; } = 24000;
}

public class SessionInfo
{
    public string SessionId { get; set; } = string.Empty;
    public DateTime CreatedAt { get; set; }
    public DateTime? LastActiveAt { get; set; }
    public RealTimeDialogState State { get; set; }
}

public class ProtocolMessage
{
    public MessageType Type { get; set; }
    public int Sequence { get; set; }
    public byte[] Payload { get; set; } = Array.Empty<byte>();
}

public enum MessageType
{
    FullClient = 1,
    AudioOnlyClient = 2,
    FullServer = 3,
    AudioOnlyServer = 4,
    Error = 5
}

public class RealTimeEventData
{
    public string EventType { get; set; } = string.Empty;
    public string Data { get; set; } = string.Empty;
    public DateTime Timestamp { get; set; } = DateTime.UtcNow;
}
```

## 3. 前端实施方案

### 3.1 重构RealTimeService

创建新的`realTimeApiService.ts`文件：

```typescript
// src/services/realTimeApiService.ts

import { API_ENDPOINTS } from '../constants';
import {
  RealTimeConfig,
  StartSessionPayload,
  RealTimeConnectionState,
  RealTimeEventData,
  SessionStatusResponse,
  CreateSessionResponse
} from '../types';

export class RealTimeApiService {
  private httpClient: typeof fetch;
  private audioWebSocket: WebSocket | null = null;
  private sessionId: string | null = null;
  private connectionState: RealTimeConnectionState = RealTimeConnectionState.Disconnected;
  private eventHandlers: Map<string, Function[]> = new Map();
  private reconnectAttempts = 0;
  private maxReconnectAttempts = 5;
  private reconnectDelay = 1000;

  constructor() {
    this.httpClient = fetch;
  }

  /**
   * 创建新的实时语音会话
   */
  async createSession(config: RealTimeConfig): Promise<string> {
    try {
      const response = await this.httpClient(API_ENDPOINTS.REALTIME.CREATE_SESSION, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          appId: config.appId,
          accessToken: config.accessToken,
          webSocketUrl: config.webSocketUrl,
          connectionTimeoutMs: config.connectionTimeoutMs,
          audioBufferSeconds: config.audioBufferSeconds
        })
      });

      if (!response.ok) {
        throw new Error(`创建会话失败: ${response.statusText}`);
      }

      const result: CreateSessionResponse = await response.json();
      this.sessionId = result.sessionId;
      
      console.log('会话创建成功:', result.sessionId);
      return result.sessionId;
    } catch (error) {
      console.error('创建会话失败:', error);
      throw error;
    }
  }

  /**
   * 启动会话
   */
  async startSession(sessionId: string, payload: StartSessionPayload): Promise<void> {
    try {
      const response = await this.httpClient(
        API_ENDPOINTS.REALTIME.START_SESSION.replace('{sessionId}', sessionId),
        {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
          },
          body: JSON.stringify(payload)
        }
      );

      if (!response.ok) {
        throw new Error(`启动会话失败: ${response.statusText}`);
      }

      this.connectionState = RealTimeConnectionState.Connected;
      this.emit('connectionStateChanged', this.connectionState);
      
      console.log('会话启动成功:', sessionId);
    } catch (error) {
      console.error('启动会话失败:', error);
      this.connectionState = RealTimeConnectionState.Error;
      this.emit('connectionStateChanged', this.connectionState);
      throw error;
    }
  }

  /**
   * 结束会话
   */
  async finishSession(sessionId: string): Promise<void> {
    try {
      if (this.audioWebSocket) {
        this.audioWebSocket.close();
        this.audioWebSocket = null;
      }

      const response = await this.httpClient(
        API_ENDPOINTS.REALTIME.FINISH_SESSION.replace('{sessionId}', sessionId),
        {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
          }
        }
      );

      if (!response.ok) {
        throw new Error(`结束会话失败: ${response.statusText}`);
      }

      this.connectionState = RealTimeConnectionState.Disconnected;
      this.sessionId = null;
      this.emit('connectionStateChanged', this.connectionState);
      
      console.log('会话结束成功:', sessionId);
    } catch (error) {
      console.error('结束会话失败:', error);
      throw error;
    }
  }

  /**
   * 获取会话状态
   */
  async getSessionStatus(sessionId: string): Promise<SessionStatusResponse> {
    try {
      const response = await this.httpClient(
        API_ENDPOINTS.REALTIME.GET_SESSION_STATUS.replace('{sessionId}', sessionId)
      );

      if (!response.ok) {
        throw new Error(`获取会话状态失败: ${response.statusText}`);
      }

      return await response.json();
    } catch (error) {
      console.error('获取会话状态失败:', error);
      throw error;
    }
  }

  /**
   * 连接音频流WebSocket
   */
  async connectAudioStream(sessionId: string): Promise<void> {
    try {
      this.connectionState = RealTimeConnectionState.Connecting;
      this.emit('connectionStateChanged', this.connectionState);

      const wsUrl = `${API_ENDPOINTS.REALTIME.WEBSOCKET.replace('{sessionId}', sessionId)}`
        .replace('http://', 'ws://')
        .replace('https://', 'wss://');

      this.audioWebSocket = new WebSocket(wsUrl);
      
      this.audioWebSocket.onopen = () => {
        console.log('WebSocket连接建立成功');
        this.connectionState = RealTimeConnectionState.Connected;
        this.reconnectAttempts = 0;
        this.emit('connectionStateChanged', this.connectionState);
      };

      this.audioWebSocket.onmessage = (event) => {
        if (event.data instanceof ArrayBuffer) {
          // 接收到音频数据
          this.emit('audioDataReceived', new Uint8Array(event.data));
        } else {
          // 接收到文本消息
          try {
            const eventData: RealTimeEventData = JSON.parse(event.data);
            this.emit('dialogEvent', eventData);
          } catch (error) {
            console.error('解析WebSocket消息失败:', error);
          }
        }
      };

      this.audioWebSocket.onerror = (error) => {
        console.error('WebSocket错误:', error);
        this.connectionState = RealTimeConnectionState.Error;
        this.emit('connectionStateChanged', this.connectionState);
        this.emit('error', error);
      };

      this.audioWebSocket.onclose = (event) => {
        console.log('WebSocket连接关闭:', event.code, event.reason);
        this.connectionState = RealTimeConnectionState.Disconnected;
        this.emit('connectionStateChanged', this.connectionState);
        
        // 自动重连
        if (event.code !== 1000 && this.reconnectAttempts < this.maxReconnectAttempts) {
          this.scheduleReconnect(sessionId);
        }
      };
    } catch (error) {
      console.error('连接WebSocket失败:', error);
      this.connectionState = RealTimeConnectionState.Error;
      this.emit('connectionStateChanged', this.connectionState);
      throw error;
    }
  }

  /**
   * 发送音频数据
   */
  async sendAudioData(audioData: ArrayBuffer): Promise<void> {
    if (this.audioWebSocket?.readyState === WebSocket.OPEN) {
      this.audioWebSocket.send(audioData);
    } else {
      console.warn('WebSocket未连接，无法发送音频数据');
    }
  }

  /**
   * 断开音频流连接
   */
  async disconnectAudioStream(): Promise<void> {
    if (this.audioWebSocket) {
      this.audioWebSocket.close(1000, '正常关闭');
      this.audioWebSocket = null;
    }
  }

  /**
   * 计划重连
   */
  private scheduleReconnect(sessionId: string): void {
    this.reconnectAttempts++;
    const delay = Math.min(this.reconnectDelay * Math.pow(2, this.reconnectAttempts - 1), 30000);
    
    console.log(`${delay}ms后尝试第${this.reconnectAttempts}次重连`);
    
    setTimeout(() => {
      this.connectAudioStream(sessionId).catch(error => {
        console.error('重连失败:', error);
      });
    }, delay);
  }

  /**
   * 事件监听
   */
  on(event: string, handler: Function): void {
    if (!this.eventHandlers.has(event)) {
      this.eventHandlers.set(event, []);
    }
    this.eventHandlers.get(event)!.push(handler);
  }

  /**
   * 移除事件监听
   */
  off(event: string, handler: Function): void {
    const handlers = this.eventHandlers.get(event);
    if (handlers) {
      const index = handlers.indexOf(handler);
      if (index > -1) {
        handlers.splice(index, 1);
      }
    }
  }

  /**
   * 触发事件
   */
  private emit(event: string, data?: any): void {
    const handlers = this.eventHandlers.get(event);
    if (handlers) {
      handlers.forEach(handler => handler(data));
    }
  }

  /**
   * 获取当前连接状态
   */
  getConnectionState(): RealTimeConnectionState {
    return this.connectionState;
  }

  /**
   * 获取当前会话ID
   */
  getCurrentSessionId(): string | null {
    return this.sessionId;
  }
}

// 导出单例实例
export const realTimeApiService = new RealTimeApiService();
```

### 3.2 音频管理服务

创建`audioManager.ts`文件：

```typescript
// src/services/audioManager.ts

export class AudioManager {
  private mediaRecorder: MediaRecorder | null = null;
  private audioContext: AudioContext | null = null;
  private audioWorklet: AudioWorkletNode | null = null;
  private mediaStream: MediaStream | null = null;
  private isRecording = false;
  private audioChunks: Blob[] = [];
  private onAudioDataCallback: ((data: ArrayBuffer) => void) | null = null;

  /**
   * 初始化音频设备
   */
  async initializeAudio(): Promise<void> {
    try {
      // 请求麦克风权限
      this.mediaStream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: 16000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      });

      // 创建音频上下文
      this.audioContext = new (window.AudioContext || (window as any).webkitAudioContext)({
        sampleRate: 16000
      });

      console.log('音频设备初始化成功');
    } catch (error) {
      console.error('初始化音频设备失败:', error);
      throw new Error('无法访问麦克风，请检查权限设置');
    }
  }

  /**
   * 开始录音
   */
  async startRecording(onAudioData: (data: ArrayBuffer) => void): Promise<void> {
    if (!this.mediaStream) {
      throw new Error('音频设备未初始化');
    }

    try {
      this.onAudioDataCallback = onAudioData;
      this.audioChunks = [];

      // 创建MediaRecorder
      this.mediaRecorder = new MediaRecorder(this.mediaStream, {
        mimeType: 'audio/webm;codecs=pcm'
      });

      this.mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          this.audioChunks.push(event.data);
          
          // 转换为ArrayBuffer并发送
          event.data.arrayBuffer().then(buffer => {
            this.convertTopcm16(buffer).then(pcmData => {
              this.onAudioDataCallback?.(pcmData);
            });
          });
        }
      };

      this.mediaRecorder.start(100); // 每100ms产生一个数据块
      this.isRecording = true;
      
      console.log('开始录音');
    } catch (error) {
      console.error('开始录音失败:', error);
      throw error;
    }
  }

  /**
   * 停止录音
   */
  async stopRecording(): Promise<void> {
    if (this.mediaRecorder && this.isRecording) {
      this.mediaRecorder.stop();
      this.isRecording = false;
      this.onAudioDataCallback = null;
      
      console.log('停止录音');
    }
  }

  /**
   * 播放音频数据
   */
  async playAudioData(audioData: ArrayBuffer): Promise<void> {
    if (!this.audioContext) {
      throw new Error('音频上下文未初始化');
    }

    try {
      // 解码音频数据
      const audioBuffer = await this.audioContext.decodeAudioData(audioData.slice(0));
      
      // 创建音频源
      const source = this.audioContext.createBufferSource();
      source.buffer = audioBuffer;
      source.connect(this.audioContext.destination);
      
      // 播放音频
      source.start();
      
      console.log('播放音频数据');
    } catch (error) {
      console.error('播放音频失败:', error);
      throw error;
    }
  }

  /**
   * 转换为PCM 16位格式
   */
  private async convertTopcm16(audioData: ArrayBuffer): Promise<ArrayBuffer> {
    if (!this.audioContext) {
      throw new Error('音频上下文未初始化');
    }

    try {
      const audioBuffer = await this.audioContext.decodeAudioData(audioData.slice(0));
      const channelData = audioBuffer.getChannelData(0);
      
      // 转换为16位PCM
      const pcm16 = new Int16Array(channelData.length);
      for (let i = 0; i < channelData.length; i++) {
        pcm16[i] = Math.max(-32768, Math.min(32767, channelData[i] * 32768));
      }
      
      return pcm16.buffer;
    } catch (error) {
      console.error('音频格式转换失败:', error);
      // 如果转换失败，直接返回原始数据
      return audioData;
    }
  }

  /**
   * 获取录音状态
   */
  isCurrentlyRecording(): boolean {
    return this.isRecording;
  }

  /**
   * 清理资源
   */
  cleanup(): void {
    if (this.mediaRecorder) {
      this.mediaRecorder.stop();
      this.mediaRecorder = null;
    }

    if (this.mediaStream) {
      this.mediaStream.getTracks().forEach(track => track.stop());
      this.mediaStream = null;
    }

    if (this.audioContext) {
      this.audioContext.close();
      this.audioContext = null;
    }

    this.isRecording = false;
    this.audioChunks = [];
    this.onAudioDataCallback = null;
    
    console.log('音频资源清理完成');
  }
}

// 导出单例实例
export const audioManager = new AudioManager();
```

### 3.3 更新API端点常量

在`constants/index.ts`中添加新的API端点：

```typescript
// 在 API_ENDPOINTS 中添加
export const API_ENDPOINTS = {
  // 现有端点...
  
  REALTIME: {
    CREATE_SESSION: '/api/realtime/session/create',
    START_SESSION: '/api/realtime/session/{sessionId}/start',
    FINISH_SESSION: '/api/realtime/session/{sessionId}/finish',
    GET_SESSION_STATUS: '/api/realtime/session/{sessionId}/status',
    START_RECORDING: '/api/realtime/session/{sessionId}/audio/start-recording',
    STOP_RECORDING: '/api/realtime/session/{sessionId}/audio/stop-recording',
    START_PLAYBACK: '/api/realtime/session/{sessionId}/audio/start-playback',
    STOP_PLAYBACK: '/api/realtime/session/{sessionId}/audio/stop-playback',
    WEBSOCKET: '/api/realtime/session/{sessionId}/websocket'
  }
};
```

### 3.4 更新类型定义

在`types/index.ts`中添加新的类型：

```typescript
// 添加到现有类型定义中

export interface CreateSessionResponse {
  sessionId: string;
  status: string;
  message: string;
}

export interface SessionStatusResponse {
  sessionId: string;
  state: string;
  createdAt: string;
  lastActiveAt?: string;
  isConnected: boolean;
}

export interface AudioManagerConfig {
  sampleRate: number;
  channelCount: number;
  echoCancellation: boolean;
  noiseSuppression: boolean;
  autoGainControl: boolean;
}

export interface RealTimeApiConfig {
  baseUrl: string;
  timeout: number;
  retryAttempts: number;
  retryDelay: number;
}
```

## 4. 配置和部署

### 4.1 后端配置

在`appsettings.json`中添加配置：

```json
{
  "RealTime": {
    "DefaultWebSocketUrl": "wss://openspeech.bytedance.com/api/v3/realtime/dialogue",
    "ConnectionTimeoutMs": 30000,
    "AudioBufferSeconds": 100,
    "MaxConcurrentSessions": 100,
    "SessionCacheExpirationHours": 1
  },
  "Logging": {
    "LogLevel": {
      "EasyVoice.Core.Services.DoubaoRealTimeService": "Debug",
      "EasyVoice.Api.Controllers.RealTimeController": "Information"
    }
  }
}
```

在`Program.cs`中注册服务：

```csharp
// 添加到 Program.cs

builder.Services.AddMemoryCache();
builder.Services.AddScoped<IDoubaoRealTimeService, DoubaoRealTimeService>();

// 配置WebSocket
builder.Services.AddWebSockets(options =>
{
    options.KeepAliveInterval = TimeSpan.FromSeconds(30);
    options.ReceiveBufferSize = 4096;
});

// 配置CORS
builder.Services.AddCors(options =>
{
    options.AddPolicy("RealTimePolicy", policy =>
    {
        policy.WithOrigins("http://localhost:3000", "https://yourdomain.com")
              .AllowAnyMethod()
              .AllowAnyHeader()
              .AllowCredentials();
    });
});

var app = builder.Build();

// 启用WebSocket
app.UseWebSockets();
app.UseCors("RealTimePolicy");
```

### 4.2 前端配置

创建环境配置文件`.env.local`：

```env
# 后端API地址
REACT_APP_API_BASE_URL=http://localhost:5000

# 豆包配置
REACT_APP_DOUBAO_APP_ID=your_app_id
REACT_APP_DOUBAO_ACCESS_TOKEN=your_access_token

# WebSocket配置
REACT_APP_WS_RECONNECT_ATTEMPTS=5
REACT_APP_WS_RECONNECT_DELAY=1000

# 音频配置
REACT_APP_AUDIO_SAMPLE_RATE=16000
REACT_APP_AUDIO_BUFFER_SIZE=4096
```

## 5. 测试和验证

### 5.1 单元测试

创建后端测试：

```csharp
// Tests/RealTimeControllerTests.cs

[TestClass]
public class RealTimeControllerTests
{
    private RealTimeController _controller;
    private Mock<IDoubaoRealTimeService> _mockService;
    private Mock<IMemoryCache> _mockCache;

    [TestInitialize]
    public void Setup()
    {
        _mockService = new Mock<IDoubaoRealTimeService>();
        _mockCache = new Mock<IMemoryCache>();
        _controller = new RealTimeController(_mockService.Object, Mock.Of<ILogger<RealTimeController>>(), _mockCache.Object);
    }

    [TestMethod]
    public async Task CreateSession_ShouldReturnSessionId()
    {
        // Arrange
        var request = new CreateSessionRequest
        {
            AppId = "test_app_id",
            AccessToken = "test_token"
        };

        // Act
        var result = await _controller.CreateSession(request);

        // Assert
        Assert.IsInstanceOfType(result, typeof(OkObjectResult));
        var okResult = result as OkObjectResult;
        var response = okResult.Value as CreateSessionResponse;
        Assert.IsNotNull(response.SessionId);
    }
}
```

创建前端测试：

```typescript
// src/services/__tests__/realTimeApiService.test.ts

import { RealTimeApiService } from '../realTimeApiService';
import { RealTimeConfig } from '../../types';

describe('RealTimeApiService', () => {
  let service: RealTimeApiService;
  
  beforeEach(() => {
    service = new RealTimeApiService();
    global.fetch = jest.fn();
  });

  afterEach(() => {
    jest.resetAllMocks();
  });

  test('should create session successfully', async () => {
    // Arrange
    const config: RealTimeConfig = {
      appId: 'test_app_id',
      accessToken: 'test_token',
      webSocketUrl: 'wss://test.com',
      connectionTimeoutMs: 30000,
      audioBufferSeconds: 100
    };

    const mockResponse = {
      sessionId: 'test_session_id',
      status: 'created',
      message: '会话创建成功'
    };

    (global.fetch as jest.Mock).mockResolvedValueOnce({
      ok: true,
      json: async () => mockResponse
    });

    // Act
    const sessionId = await service.createSession(config);

    // Assert
    expect(sessionId).toBe('test_session_id');
    expect(global.fetch).toHaveBeenCalledWith(
      expect.stringContaining('/api/realtime/session/create'),
      expect.objectContaining({
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          appId: config.appId,
          accessToken: config.accessToken,
          webSocketUrl: config.webSocketUrl,
          connectionTimeoutMs: config.connectionTimeoutMs,
          audioBufferSeconds: config.audioBufferSeconds
        })
      })
    );
  });
});
```

### 5.2 集成测试

创建端到端测试脚本：

```typescript
// e2e/realtime-integration.test.ts

import { realTimeApiService } from '../src/services/realTimeApiService';
import { audioManager } from '../src/services/audioManager';

describe('实时语音对话集成测试', () => {
  let sessionId: string;

  beforeAll(async () => {
    // 初始化音频设备
    await audioManager.initializeAudio();
  });

  afterAll(() => {
    // 清理资源
    audioManager.cleanup();
  });

  test('完整的语音对话流程', async () => {
    // 1. 创建会话
    sessionId = await realTimeApiService.createSession({
      appId: process.env.REACT_APP_DOUBAO_APP_ID!,
      accessToken: process.env.REACT_APP_DOUBAO_ACCESS_TOKEN!,
      webSocketUrl: 'wss://openspeech.bytedance.com/api/v3/realtime/dialogue',
      connectionTimeoutMs: 30000,
      audioBufferSeconds: 100
    });

    expect(sessionId).toBeTruthy();

    // 2. 启动会话
    await realTimeApiService.startSession(sessionId, {
      tts: {
        audioConfig: {
          channel: 1,
          format: 'pcm',
          sampleRate: 24000
        }
      },
      dialog: {
        botName: '豆包',
        systemRole: '你是一个友好的AI助手',
        speakingStyle: '简洁明了'
      }
    });

    // 3. 连接WebSocket
    await realTimeApiService.connectAudioStream(sessionId);

    // 4. 模拟音频数据发送
    const mockAudioData = new ArrayBuffer(1024);
    await realTimeApiService.sendAudioData(mockAudioData);

    // 5. 等待响应
    await new Promise(resolve => setTimeout(resolve, 2000));

    // 6. 结束会话
    await realTimeApiService.finishSession(sessionId);
  }, 30000);
});
```

## 6. 监控和日志

### 6.1 性能监控

添加性能指标收集：

```csharp
// 在 DoubaoRealTimeService 中添加

public class PerformanceMetrics
{
    public TimeSpan ConnectionTime { get; set; }
    public TimeSpan AudioLatency { get; set; }
    public int PacketLossCount { get; set; }
    public double AudioQualityScore { get; set; }
    public int ConcurrentSessions { get; set; }
}

public class MetricsCollector
{
    private readonly ILogger<MetricsCollector> _logger;
    
    public void RecordConnectionTime(TimeSpan duration)
    {
        _logger.LogInformation("连接建立时间: {Duration}ms", duration.TotalMilliseconds);
    }
    
    public void RecordAudioLatency(TimeSpan latency)
    {
        _logger.LogInformation("音频延迟: {Latency}ms", latency.TotalMilliseconds);
    }
}
```

### 6.2 错误监控

实现错误追踪：

```typescript
// src/utils/errorTracker.ts

export class ErrorTracker {
  static trackError(error: Error, context: string): void {
    console.error(`[${context}] 错误:`, error);
    
    // 发送错误到监控服务
    if (process.env.NODE_ENV === 'production') {
      // 集成Sentry或其他错误监控服务
      // Sentry.captureException(error, { tags: { context } });
    }
  }
  
  static trackPerformance(metric: string, value: number): void {
    console.log(`[性能指标] ${metric}: ${value}`);
    
    // 发送性能数据到监控服务
    if (process.env.NODE_ENV === 'production') {
      // 发送到分析服务
    }
  }
}
```

## 7. 部署指南

### 7.1 Docker部署

创建`Dockerfile`：

```dockerfile
# 后端Dockerfile
FROM mcr.microsoft.com/dotnet/aspnet:8.0 AS base
WORKDIR /app
EXPOSE 80
EXPOSE 443

FROM mcr.microsoft.com/dotnet/sdk:8.0 AS build
WORKDIR /src
COPY ["EasyVoice.Api/EasyVoice.Api.csproj", "EasyVoice.Api/"]
COPY ["EasyVoice.Core/EasyVoice.Core.csproj", "EasyVoice.Core/"]
RUN dotnet restore "EasyVoice.Api/EasyVoice.Api.csproj"
COPY . .
WORKDIR "/src/EasyVoice.Api"
RUN dotnet build "EasyVoice.Api.csproj" -c Release -o /app/build

FROM build AS publish
RUN dotnet publish "EasyVoice.Api.csproj" -c Release -o /app/publish

FROM base AS final
WORKDIR /app
COPY --from=publish /app/publish .
ENTRYPOINT ["dotnet", "EasyVoice.Api.dll"]
```

创建`docker-compose.yml`：

```yaml
version: '3.8'

services:
  easyvoice-api:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "5000:80"
    environment:
      - ASPNETCORE_ENVIRONMENT=Production
      - RealTime__DefaultWebSocketUrl=wss://openspeech.bytedance.com/api/v3/realtime/dialogue
    volumes:
      - ./logs:/app/logs
    restart: unless-stopped

  easyvoice-frontend:
    build:
      context: ./frontend-react
      dockerfile: Dockerfile
    ports:
      - "3000:80"
    environment:
      - REACT_APP_API_BASE_URL=http://localhost:5000
    depends_on:
      - easyvoice-api
    restart: unless-stopped

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - easyvoice-api
      - easyvoice-frontend
    restart: unless-stopped
```

### 7.2 Nginx配置

创建`nginx.conf`：

```nginx
events {
    worker_connections 1024;
}

http {
    upstream api_backend {
        server easyvoice-api:80;
    }
    
    upstream frontend_backend {
        server easyvoice-frontend:80;
    }
    
    server {
        listen 80;
        server_name localhost;
        
        # 前端静态文件
        location / {
            proxy_pass http://frontend_backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
        }
        
        # API接口
        location /api/ {
            proxy_pass http://api_backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            
            # WebSocket支持
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
            proxy_read_timeout 86400;
        }
    }
}
```

这个实施方案提供了完整的前后端对接解决方案，确保实时语音对话功能的稳定性和高可用性。通过HTTP API管理会话生命周期，WebSocket处理实时音频流，实现了高效的实时语音交互体验。